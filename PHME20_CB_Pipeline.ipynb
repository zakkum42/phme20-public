{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHME20 Data Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Dataset Configuration Parameters](#dataset-configuration-parameters)\n",
    "* [Global Parameters](#global-parameters)\n",
    "* [Utility Functions](#utility-functions)\n",
    "* [RUL Assignment](#rul-assignment)\n",
    "* [Machine Learning Models](#ml-models)\n",
    "    * [Cross Validation](#ml-cross-validation)\n",
    "    * [Training](#ml-training)\n",
    "    * [Evaluation](#ml-evaluation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.scores import MLE, CRPS\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sacred import Experiment\n",
    "from sacred.commands import print_config\n",
    "from sacred.observers import FileStorageObserver\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment('PHME20', interactive=True)\n",
    "ex.observers.append(FileStorageObserver('CB_kmeans/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Configuration Parameters <a class=\"anchor\" id=\"dataset-configuration-parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./input/\"\n",
    "\n",
    "train_small_path = input_path + \"Training/Small/\"\n",
    "train_large_path = input_path + \"Training/Large/\"\n",
    "validation_small_path = input_path + \"Validation/Small/\"\n",
    "validation_large_path = input_path + \"Validation/Large/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "     1: {'path': train_small_path, 'size': 1, 'ratio': 0.4, 'profile': 1},\n",
    "     2: {'path': train_small_path, 'size': 1, 'ratio': 0.4, 'profile': 1},\n",
    "     3: {'path': train_small_path, 'size': 1, 'ratio': 0.4, 'profile': 1},\n",
    "     4: {'path': train_small_path, 'size': 1, 'ratio': 0.4, 'profile': 1},\n",
    "    \n",
    "     5: {'path': train_small_path, 'size': 1, 'ratio': 0.425, 'profile': 2},\n",
    "     6: {'path': train_small_path, 'size': 1, 'ratio': 0.425, 'profile': 2},\n",
    "     7: {'path': train_small_path, 'size': 1, 'ratio': 0.425, 'profile': 2},\n",
    "     8: {'path': train_small_path, 'size': 1, 'ratio': 0.425, 'profile': 2},\n",
    "\n",
    "     9: {'path': train_small_path, 'size': 1, 'ratio': 0.45, 'profile': 3},\n",
    "    10: {'path': train_small_path, 'size': 1, 'ratio': 0.45, 'profile': 3},\n",
    "    11: {'path': train_small_path, 'size': 1, 'ratio': 0.45, 'profile': 3},\n",
    "    12: {'path': train_small_path, 'size': 1, 'ratio': 0.45, 'profile': 3},\n",
    "    \n",
    "    13: {'path': validation_small_path, 'size': 1, 'ratio': 0.475, 'profile': 4},\n",
    "    14: {'path': validation_small_path, 'size': 1, 'ratio': 0.475, 'profile': 4},\n",
    "    15: {'path': validation_small_path, 'size': 1, 'ratio': 0.475, 'profile': 4},\n",
    "    16: {'path': validation_small_path, 'size': 1, 'ratio': 0.475, 'profile': 4},\n",
    "    \n",
    "    33: {'path': train_large_path, 'size': 3, 'ratio': 0.4, 'profile': 9},\n",
    "    34: {'path': train_large_path, 'size': 3, 'ratio': 0.4, 'profile': 9},\n",
    "    35: {'path': train_large_path, 'size': 3, 'ratio': 0.4, 'profile': 9},\n",
    "    36: {'path': train_large_path, 'size': 3, 'ratio': 0.4, 'profile': 9},\n",
    "    \n",
    "    37: {'path': train_large_path, 'size': 3, 'ratio': 0.425, 'profile': 10},\n",
    "    38: {'path': train_large_path, 'size': 3, 'ratio': 0.425, 'profile': 10},\n",
    "    39: {'path': train_large_path, 'size': 3, 'ratio': 0.425, 'profile': 10},\n",
    "    40: {'path': train_large_path, 'size': 3, 'ratio': 0.425, 'profile': 10},\n",
    "                                    \n",
    "    41: {'path': train_large_path, 'size': 3, 'ratio': 0.45, 'profile': 11},\n",
    "    42: {'path': train_large_path, 'size': 3, 'ratio': 0.45, 'profile': 11},\n",
    "    43: {'path': train_large_path, 'size': 3, 'ratio': 0.45, 'profile': 11},\n",
    "    44: {'path': train_large_path, 'size': 3, 'ratio': 0.45, 'profile': 11},\n",
    "\n",
    "    45: {'path': validation_large_path, 'size': 3, 'ratio': 0.475, 'profile': 12},\n",
    "    46: {'path': validation_large_path, 'size': 3, 'ratio': 0.475, 'profile': 12},\n",
    "    47: {'path': validation_large_path, 'size': 3, 'ratio': 0.475, 'profile': 12},                                 \n",
    "    48: {'path': validation_large_path, 'size': 3, 'ratio': 0.475, 'profile': 12},                                 \n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_for_training = {\n",
    "    25 : ([1, 5, 9, 33, 37, 41],\n",
    "          [13, 14, 15, 16, 45, 46, 47, 48]),\n",
    "    50 : ([1, 2, 5, 6, 9, 10, 33, 34, 37, 38, 41, 42],\n",
    "          [13, 14, 15, 16, 45, 46, 47, 48]),\n",
    "    75 : ([1, 2, 3, 5, 6, 7, 9, 10, 11, 33, 34, 35, 37, 38, 39, 41, 42, 43],\n",
    "          [13, 14, 15, 16, 45, 46, 47, 48]),\n",
    "    100: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
    "          [13, 14, 15, 16, 45, 46, 47, 48]),\n",
    "}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    25: 'model_4_25_percent.pkl',\n",
    "    50: 'model_3_50_percent.pkl',\n",
    "    75: 'model_2_75_percent.pkl',\n",
    "    100: 'model_1_all_experiements.pkl',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameters <a class=\"anchor\" id=\"global-parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def configuration_settings():\n",
    "    RUL_Max = 150 # seconds!\n",
    "    scale_type = \"standard\"\n",
    "    RUL_Assignment_Method = \"Linear\"\n",
    "    window_size = 5\n",
    "    train_model = True\n",
    "    eval_model = True\n",
    "    data_percent = 1\n",
    "    training_list, validating_list = experiments_for_training[data_percent]\n",
    "    final_model_path = model_names[data_percent]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "RUL_Assignment = None\n",
    "GLOBAL_INIT_RUL = None # seconds!\n",
    "\n",
    "# Main sensor list. \n",
    "# List shall include other features such as operating conditions. \n",
    "sensor_list = ['Flow_Rate', 'Upstream_Pressure', 'Downstream_Pressure', 'Pressure_Drop']\n",
    "feature_list = ['Flow_Rate', 'Upstream_Pressure', 'Downstream_Pressure', 'Pressure_Drop', 'Particle_Size', 'Ratio', 'Kmeans_Profile']\n",
    "experiment_params = ['Particle_Size', 'Ratio']\n",
    "n_profiles = 6\n",
    "\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions <a class=\"anchor\" id=\"utility-functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fault estimation from line detection\n",
    "def fault_estimation(experiment_df, ws=3):\n",
    "    flow_rate = running_mean(experiment_df.Flow_Rate.values, ws)\n",
    "    count = flow_rate.shape[0]\n",
    "\n",
    "    x_fr = list(range(flow_rate.shape[0]))\n",
    "\n",
    "    # fit a polygon for readings b/w 400 and 1400\n",
    "    z0 = np.polyfit(x_fr[400:1400], flow_rate[400:1400], 1) \n",
    "#     print (z0)\n",
    "\n",
    "    line_func = np.poly1d(z0) # create function flow line params\n",
    "    line = line_func(x_fr) # fit a line for polygon\n",
    "\n",
    "    y_diff = line - flow_rate\n",
    "    y_diff_rev = y_diff[::-1] # reverse the points of line\n",
    "\n",
    "    # Find where the line intersects the Flow_Rate\n",
    "    index = np.argmax(y_diff_rev < 0) \n",
    "    intersection = count - index \n",
    "\n",
    "    return int(intersection.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences based on window size\n",
    "def create_sequence(sequence, window_size):\n",
    "    X = list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + window_size\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequence[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "    return np.array(X)\n",
    " \n",
    "\n",
    "# Create dataset for experiment\n",
    "def create_dataset_for_experiment(df, ws):\n",
    "    data_data = np.empty((0, ws * len(feature_list)), dtype=np.float32) # for 1D\n",
    "    rul_data = np.empty((0, 1), dtype=np.int)\n",
    "\n",
    "    experiment_list = df.ExperimentID.unique()\n",
    "    \n",
    "    for experiment in experiment_list:\n",
    "        experiment_df = df[df['ExperimentID'] == experiment]\n",
    "        sensors_df = experiment_df.filter(feature_list)\n",
    "\n",
    "        # Calculate seq of windows_size len\n",
    "        seq = create_sequence(sensors_df.values, window_size=ws)\n",
    "        seq_count = seq.shape[0]\n",
    "        seq = seq.reshape((seq_count, -1)) # for 1D\n",
    "\n",
    "        # add new seq to data_data array\n",
    "        data_data = np.vstack((data_data, seq))\n",
    "\n",
    "        # Calculate RULS\n",
    "        rul_df = experiment_df[RUL_Assignment] * 1.0 #?\n",
    "        ruls = rul_df.values[-seq_count:].reshape((seq_count, -1))\n",
    "\n",
    "        # add rul to rul_data array\n",
    "        rul_data = np.vstack((rul_data, ruls))\n",
    "\n",
    "    return data_data, rul_data\n",
    "#     return data_data, (rul_data - 75) / 75\n",
    "\n",
    "# create dataset wrapper\n",
    "def create_datasets(df, ws):\n",
    "    sensor_data, rul_data = create_dataset_for_experiment(df, ws)\n",
    "\n",
    "    padded_sensor_data = sensor_data.copy() \n",
    "\n",
    "    # Calculate X(t) \n",
    "    X_t = padded_sensor_data.copy()\n",
    "\n",
    "    # Calculate y(t) \n",
    "    y_t = rul_data.copy()\n",
    "\n",
    "    return X_t, y_t \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScaler(object):\n",
    "    \n",
    "    def get_scaler(self, scaler_name=None):\n",
    "        ret = None\n",
    "        if scaler_name == 'standard':\n",
    "            ret = StandardScaler()\n",
    "        elif scaler_name == 'minmax':\n",
    "            ret = MinMaxScaler()\n",
    "        elif scaler_name == 'minmax01':\n",
    "            ret = MinMaxScaler()\n",
    "        elif scaler_name == 'minmax-11':\n",
    "            ret = MinMaxScaler(feature_range=(-1,1))\n",
    "        elif scaler_name == 'robust':\n",
    "            ret = RobustScaler()\n",
    "        return ret\n",
    "\n",
    "    def __init__(self, scaler_name):\n",
    "        self.profiles = []\n",
    "        self.scalers = []\n",
    "        self.scaler_name = scaler_name\n",
    "    \n",
    "    def fit(self, X_df, y=0):\n",
    "        self.scalers = {}\n",
    "        self.profiles = X_df['Kmeans_Profile'].unique()\n",
    "        # Full dataset fit\n",
    "        for profile in self.profiles:\n",
    "            sensors_readings = X_df[(X_df['Kmeans_Profile']==profile)].filter(sensor_list)          # Get sensor readings\n",
    "            state_scaler = self.get_scaler(self.scaler_name).fit(sensors_readings)              # Fit scaler\n",
    "            self.scalers[profile] = state_scaler                                                   # Add to sclaer_list for further reference\n",
    "        \n",
    "        return self\n",
    "     \n",
    "    def transform(self, X_df, y=0):\n",
    "        # Full dataset transform\n",
    "        for profile in self.profiles:\n",
    "            sensors_readings = X_df[(X_df['Kmeans_Profile']==profile)].filter(sensor_list)          # Get sensor readings\n",
    "            if (sensors_readings.shape[0] == 0): continue # No matching profiles found in X_df\n",
    "            cols = sensors_readings.columns\n",
    "            normalized_sensor_readings = self.scalers[profile].transform(sensors_readings)      # transform sensor readings\n",
    "            X_df.loc[(X_df['Kmeans_Profile']==profile), cols] = normalized_sensor_readings                  # record transformed values\n",
    "\n",
    "        return X_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUL Assignment <a class=\"anchor\" id=\"rul-assignment\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this challenge we construct Linear, Piecewise Linear (PwL), and rounded PwL. We will use the one that generates minimum penalty score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create extra features for each data file, and generate a DataFrame.\n",
    "#\n",
    "def convert_to_df(experimentId, path=None, size=1, ratio=0.4, profile=0):\n",
    "# Initial columns for the data.\n",
    "    cols = ['Time', 'Flow_Rate', \"Upstream_Pressure\", \"Downstream_Pressure\"]\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    fname = path + \"Sample\" + str(experimentId).zfill(2) + \".csv\"\n",
    "    if verbose: print (\"Reading:\", fname)\n",
    "        \n",
    "    temp_df = pd.read_csv(fname)\n",
    "    temp_df.columns = cols\n",
    "# count is the number of readings for the experiment\n",
    "    count = temp_df['Time'].count()\n",
    "    temp_df['ExperimentID'] = experimentId\n",
    "    temp_df['ReadingID'] = list(range(1, count+1))\n",
    "    temp_df['Particle_Size'] = size\n",
    "    temp_df['Ratio'] = ratio\n",
    "    temp_df['Profile'] = profile\n",
    "    temp_df['Pressure_Drop'] = temp_df.Upstream_Pressure - temp_df.Downstream_Pressure\n",
    "\n",
    "# Find the clogged index\n",
    "    index = np.argmax(running_mean(temp_df.Pressure_Drop.values, 5) > 20)\n",
    "\n",
    "# Linear RUL Assignment\n",
    "    temp_df['Linear'] = None # in seconds\n",
    "    pos_rul_list = [c for c in range(index+1)]\n",
    "    pos_rul_list.reverse()\n",
    "    temp_df.iloc[:index+1, temp_df.columns.get_loc('Linear')] = pos_rul_list\n",
    "    neg_rul_list = [-c for c in range(count - index)]\n",
    "    temp_df.iloc[index:, temp_df.columns.get_loc('Linear')] = neg_rul_list\n",
    "    temp_df['Linear'] = temp_df['Linear'] / 10.0 # Sampled at 10 Hz\n",
    "\n",
    "# Piecewise Linear (PwL) RUL Assignment\n",
    "    temp_df['PwL'] = temp_df['Linear'].copy()\n",
    "    temp_df.loc[temp_df['PwL'] > GLOBAL_INIT_RUL, 'PwL'] = GLOBAL_INIT_RUL\n",
    "\n",
    "# PwL through fault\n",
    "    temp_df['PwL_Fault'] = temp_df['Linear'].copy()\n",
    "    f_index = fault_estimation(temp_df)\n",
    "    max_rul_for_exp = temp_df.iloc[f_index].Linear\n",
    "    \n",
    "    # fit a line b/w (0, GLOBAL_INIT_RUL) and (f_index, max_rul_for_exp)\n",
    "#     print ([0, f_index], [GLOBAL_INIT_RUL, max_rul_for_exp])\n",
    "    z0 = np.polyfit([0, f_index], [GLOBAL_INIT_RUL, max_rul_for_exp], 1) \n",
    "\n",
    "    line_func = np.poly1d(z0) # create function flow line params\n",
    "    x_line = line_func(list(range(f_index-1))).round(1) #.astype(np.int)\n",
    "\n",
    "    temp_df.iloc[:f_index-1, temp_df.columns.get_loc(\"PwL_Fault\")] = x_line\n",
    "\n",
    "    df = pd.concat([df, temp_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset into a DataFrame\n",
    "def load_dataset(dataset_list):\n",
    "    print (\"Loading:\", dataset_list)\n",
    "\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for e in dataset_list:\n",
    "        df = convert_to_df(e, **dataset_params[e])\n",
    "        dataset_df = pd.concat([dataset_df, df], ignore_index=True)\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_model(train_df):\n",
    "    sample_df = train_df.sample(frac=0.05)\n",
    "    X_train_for_kmeans = sample_df[experiment_params].values\n",
    "    kmeans_model = KMeans(n_clusters=n_profiles, max_iter=10)\n",
    "    kmeans_model.fit_predict(X_train_for_kmeans)\n",
    "\n",
    "    return kmeans_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training <a class=\"anchor\" id=\"ml-training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_fn(train_df, scale_type, window_size, final_model_path):\n",
    "    print (\"Final training started...\")\n",
    "\n",
    "    X_train_df = train_df.copy()\n",
    "\n",
    "    kmeans_model = get_kmeans_model(X_train_df)\n",
    "\n",
    "    X_train_df['Kmeans_Profile'] = kmeans_model.predict(X_train_df[experiment_params].values)\n",
    "    \n",
    "    preprocessing_pipe = Pipeline([('scaler', DataScaler(scale_type))])\n",
    "\n",
    "    # Transform training and validation datasets        \n",
    "    X_train_df = preprocessing_pipe.fit(X_train_df).transform(X_train_df)\n",
    "\n",
    "    X_train_t, y_train= create_datasets(X_train_df, window_size)\n",
    "    X_train_t = X_train_t.astype(np.float32) \n",
    "\n",
    "    if verbose: \n",
    "        print (X_train_t.shape, y_train.shape)        \n",
    "        print(\"---------------------------\")\n",
    "\n",
    "    # Model initialization        \n",
    "\n",
    "    model = CatBoostRegressor(iterations=1000, thread_count=8)    \n",
    "    model.fit(X=X_train_t, y=y_train, verbose=False) \n",
    "\n",
    "    pickle.dump((kmeans_model, preprocessing_pipe, model), open(final_model_path, \"wb\"))\n",
    "\n",
    "    print('Training done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation <a class=\"anchor\" id=\"ml-evaluation\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_fn(validation_df, scale_type, window_size, final_model_path):\n",
    "    print (\"Final evaluation started...\")\n",
    "\n",
    "    with open(final_model_path, \"rb\") as f:\n",
    "        kmeans_model, preprocessing_pipe, model = pickle.load(f)\n",
    "\n",
    "    X_val_df = validation_df.copy()\n",
    "\n",
    "    X_val_df['Kmeans_Profile'] = kmeans_model.predict(X_val_df[experiment_params].values)\n",
    "    \n",
    "    # This should be the proper way of scaling data:\n",
    "    X_val_df = preprocessing_pipe.transform(X_val_df)\n",
    "\n",
    "\n",
    "    X_val_t, y_val = create_datasets(X_val_df, window_size)\n",
    "    X_val_t = X_val_t.astype(np.float32) \n",
    "\n",
    "    if verbose: \n",
    "        print (X_val_t.shape, y_val.shape)        \n",
    "        print(\"---------------------------\")\n",
    "\n",
    "    test_prediction = model.predict(X_val_t) \n",
    "\n",
    "    result = mean_absolute_error((y_val)[::100], test_prediction[::100])\n",
    "    print ('Evaluation done.')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUL assignment methods\n",
    "ram_list1 = ['Linear'] # Neutral from RUL_Max\n",
    "ram_list2 = ['PwL', 'PwL_Fault']\n",
    "\n",
    "# Other hiperparameters\n",
    "dp_list = [25, 50, 75, 100] # Data percentage\n",
    "rm_list = [100, 125, 150] # RUL Max\n",
    "ws_list = [5, 10, 15, 20, 25, 30, 40, 50] # Window size\n",
    "\n",
    "total_runs = len(ram_list1) * len(dp_list) * len(ws_list) + \\\n",
    "                len(ram_list2) * len(dp_list) * len(rm_list) * len(ws_list)\n",
    "\n",
    "run_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def ex_main(_run, RUL_Max, scale_type, RUL_Assignment_Method, window_size, train_model, eval_model,\n",
    "         data_percent, training_list, validating_list, final_model_path):\n",
    "\n",
    "    global RUL_Assignment\n",
    "    global GLOBAL_INIT_RUL\n",
    "    global results_df\n",
    "    global total_runs\n",
    "    global run_counter\n",
    "    \n",
    "    print ('===========================================================================')\n",
    "    print ('Run:', run_counter+1, '/', total_runs)\n",
    "    print ('RAM:', RUL_Assignment_Method, 'DP:', data_percent, 'RM:', RUL_Max, 'WS:', window_size)\n",
    "    run_counter += 1\n",
    "    \n",
    "#     print_config(_run)\n",
    "    RUL_Assignment = RUL_Assignment_Method\n",
    "    GLOBAL_INIT_RUL = RUL_Max\n",
    "    \n",
    "    \n",
    "    if (train_model):\n",
    "        train_df = load_dataset(training_list)\n",
    "        train_model_fn(train_df, scale_type, window_size, final_model_path)\n",
    "    \n",
    "    if (eval_model):\n",
    "        validation_df = load_dataset(validating_list)\n",
    "        score = evaluate_model_fn(validation_df, scale_type, window_size, final_model_path)\n",
    "        \n",
    "        result = {\n",
    "            'ML_Algorithm': 'CatBoost',\n",
    "            'RUL_Max': RUL_Max,\n",
    "            'scale_type': scale_type,\n",
    "            'RUL_Assignment_Method': RUL_Assignment_Method,\n",
    "            'window_size': window_size,\n",
    "            'data_percent': data_percent,\n",
    "            'score': score\n",
    "        }\n",
    "        print (score)\n",
    "        results_df = results_df.append(result, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Takes ~1 hr. on Intel® Xeon® Processor E5-1660 @ 3.2 GHz\n",
    "\n",
    "# Linear RUL Assignment\n",
    "for rm in [150]:\n",
    "    for ram in ram_list1:\n",
    "        for dp in dp_list:\n",
    "            for ws in ws_list:\n",
    "                ex.run(config_updates={'RUL_Assignment_Method':ram,\n",
    "                       'data_percent': dp,\n",
    "                       'RUL_Max': rm, \n",
    "                       'window_size': ws,\n",
    "                      })\n",
    "                results_df.to_excel(\"CB_results_kmeans_profile+.xlsx\")\n",
    "\n",
    "# PwL & PwL_Fault RUL Assignment                    \n",
    "for rm in rm_list:\n",
    "    for ram in ram_list2:\n",
    "        for dp in dp_list:\n",
    "            for ws in ws_list:\n",
    "                ex.run(config_updates={'RUL_Assignment_Method':ram,\n",
    "                       'data_percent': dp,\n",
    "                       'RUL_Max': rm, \n",
    "                       'window_size': ws,\n",
    "                      })\n",
    "                results_df.to_excel(\"CB_results_kmeans_profile+.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
